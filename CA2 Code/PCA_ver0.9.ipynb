{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e48b0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with 40-dimensional:\n",
      "Train Accuracy = 71.71%, Test Accuracy = 0.65%\n",
      "\n",
      "Testing with 80-dimensional:\n",
      "Train Accuracy = 73.39%, Test Accuracy = 0.65%\n",
      "\n",
      "Testing with 200-dimensional:\n",
      "Train Accuracy = 74.23%, Test Accuracy = 0.65%\n"
     ]
    }
   ],
   "source": [
    "#method 1\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# path\n",
    "pie_path = r'D:\\University\\NUS\\EE5907\\PIE'\n",
    "self_path = r'D:\\University\\NUS\\EE5907\\self'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# load 25 subjects and self\n",
    "count = 0\n",
    "selected_subjects = set()\n",
    "images_per_subject = 20\n",
    "\n",
    "while count < 500:\n",
    "    subject_folder = np.random.choice(os.listdir(pie_path))\n",
    "    if subject_folder not in selected_subjects:\n",
    "        selected_subjects.add(subject_folder)\n",
    "        subject_path = os.path.join(pie_path, subject_folder)\n",
    "        if os.path.isdir(subject_path):\n",
    "            image_files = os.listdir(subject_path)\n",
    "            image_files = np.random.choice(image_files, min(images_per_subject, len(image_files)), replace=False)\n",
    "            for image_file in image_files:\n",
    "                if count >= 500:\n",
    "                    break\n",
    "                image_path = os.path.join(subject_path, image_file)\n",
    "                img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                img_flat = img.flatten()\n",
    "                data.append(img_flat)\n",
    "                labels.append(subject_folder)\n",
    "                count += 1\n",
    "\n",
    "for image_file in os.listdir(self_path):\n",
    "    image_path = os.path.join(self_path, image_file)\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_flat = img.flatten()\n",
    "    data.append(img_flat)\n",
    "    labels.append(\"self\")\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "data_standardized = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "cov_matrix = np.cov(data_standardized.T)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "eigenvalues = eigenvalues.real\n",
    "eigenvectors = eigenvectors.real\n",
    "\n",
    "# \n",
    "top_eigenvectors_40 = eigenvectors[:, :40]\n",
    "top_eigenvectors_80 = eigenvectors[:, :80]\n",
    "top_eigenvectors_200 = eigenvectors[:, :200]\n",
    "\n",
    "data_pca_40 = np.dot(data_standardized, top_eigenvectors_40)\n",
    "data_pca_80 = np.dot(data_standardized, top_eigenvectors_80)\n",
    "data_pca_200 = np.dot(data_standardized, top_eigenvectors_200)\n",
    "\n",
    "# divide train and test set\n",
    "train_ratio = 0.7\n",
    "train_size = int(train_ratio * data.shape[0])\n",
    "train_data, test_data = data_standardized[:train_size, :], data_standardized[train_size:, :]\n",
    "train_labels, test_labels = labels[:train_size], labels[train_size:]\n",
    "\n",
    "\n",
    "label_mapping = {label: i for i, label in enumerate(np.unique(train_labels))}\n",
    "inverse_label_mapping = {i: label for label, i in label_mapping.items()}\n",
    "\n",
    "# KNN\n",
    "def knn_predict(train_data, train_labels, test_data):\n",
    "    distances = cdist(test_data, train_data, 'euclidean')\n",
    "    nearest_neighbors = np.argsort(distances, axis=1)[:, :3]\n",
    "    \n",
    "    train_labels_int = np.array([label_mapping[label] for label in train_labels])\n",
    "    predicted_labels = np.apply_along_axis(lambda x: np.argmax(np.bincount(x)), axis=1, arr=train_labels_int[nearest_neighbors])\n",
    "    \n",
    "    predicted_labels = np.array([inverse_label_mapping[i] for i in predicted_labels])\n",
    "    \n",
    "    return predicted_labels\n",
    "\n",
    "# test\n",
    "for data_pca, dim in zip([data_pca_40, data_pca_80, data_pca_200], [40, 80, 200]):\n",
    "    print(f\"\\nTesting with {dim}-dimensional:\")\n",
    "    \n",
    "    train_predicted_labels = knn_predict(data_pca[:train_size, :], train_labels, data_pca[:train_size, :])\n",
    "    train_accuracy = np.mean(train_predicted_labels == train_labels)\n",
    "    test_predicted_labels = knn_predict(data_pca[:train_size, :], train_labels, data_pca[train_size:, :])\n",
    "    test_accuracy = np.mean(test_predicted_labels == test_labels)\n",
    "    \n",
    "    print(f\"Train Accuracy = {train_accuracy:.2%}, Test Accuracy = {test_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e215991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with 40-dimensional PCA data:\n",
      "Train Accuracy = 0.6164, Test Accuracy = 0.0000\n",
      "\n",
      "Testing with 80-dimensional PCA data:\n",
      "Train Accuracy = 0.6282, Test Accuracy = 0.0000\n",
      "\n",
      "Testing with 200-dimensional PCA data:\n",
      "Train Accuracy = 0.6419, Test Accuracy = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13104\\AppData\\Local\\Temp\\ipykernel_8256\\3514135044.py:136: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  test_accuracy = np.mean(test_predicted_labels == test_labels)\n"
     ]
    }
   ],
   "source": [
    "# method 2\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "pie_path = r'D:\\University\\NUS\\EE5907\\PIE'\n",
    "self_path = r'D:\\University\\NUS\\EE5907\\self'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "count = 0\n",
    "selected_subjects = set()\n",
    "images_per_subject = 20\n",
    "\n",
    "while count < 500:\n",
    "    subject_folder = np.random.choice(os.listdir(pie_path))\n",
    "    if subject_folder not in selected_subjects:\n",
    "        selected_subjects.add(subject_folder)\n",
    "        subject_path = os.path.join(pie_path, subject_folder)\n",
    "        if os.path.isdir(subject_path):\n",
    "            image_files = os.listdir(subject_path)\n",
    "            image_files = np.random.choice(image_files, images_per_subject, replace=False)\n",
    "            for i, image_file in enumerate(image_files):\n",
    "                image_path = os.path.join(subject_path, image_file)\n",
    "                img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                img_flat = img.flatten()\n",
    "                data.append(img_flat)\n",
    "                labels.append(subject_folder)\n",
    "                count += 1\n",
    "                if i >= 13:\n",
    "                    break\n",
    "\n",
    "# load self\n",
    "self_images = os.listdir(self_path)\n",
    "self_images = np.random.choice(self_images, 10, replace=False)\n",
    "for i, image_file in enumerate(self_images):\n",
    "    image_path = os.path.join(self_path, image_file)\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_flat = img.flatten()\n",
    "    data.append(img_flat)\n",
    "    labels.append(\"self\")\n",
    "    if i >= 6:\n",
    "        break\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "data_standardized = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "cov_matrix = np.cov(data_standardized.T)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "eigenvalues = eigenvalues.real\n",
    "eigenvectors = eigenvectors.real\n",
    "\n",
    "top_eigenvectors_40 = eigenvectors[:, :40]\n",
    "top_eigenvectors_80 = eigenvectors[:, :80]\n",
    "top_eigenvectors_200 = eigenvectors[:, :200]\n",
    "\n",
    "data_pca_40 = np.dot(data_standardized, top_eigenvectors_40)\n",
    "data_pca_80 = np.dot(data_standardized, top_eigenvectors_80)\n",
    "data_pca_200 = np.dot(data_standardized, top_eigenvectors_200)\n",
    "\n",
    "# label\n",
    "unique_labels = np.unique(labels)\n",
    "label_mapping = {label: i for i, label in enumerate(unique_labels)}\n",
    "inverse_label_mapping = {i: label for label, i in label_mapping.items()}\n",
    "\n",
    "# devide test set\n",
    "train_data_indices = np.array([], dtype=int)\n",
    "test_data_indices = np.array([], dtype=int)\n",
    "\n",
    "for subject_folder in selected_subjects:\n",
    "    subject_indices = np.where(labels == subject_folder)[0]\n",
    "    train_data_indices = np.concatenate((train_data_indices, subject_indices[:14]))\n",
    "    test_data_indices = np.concatenate((test_data_indices, subject_indices[14:]))\n",
    "\n",
    "train_data_indices = np.concatenate((train_data_indices, np.where(labels == \"self\")[0][:7]))\n",
    "test_data_indices = np.concatenate((test_data_indices, np.where(labels == \"self\")[0][7:]))\n",
    "\n",
    "# knn\n",
    "def knn_predict(train_data, train_labels, test_data):\n",
    "    distances = cdist(test_data, train_data, 'euclidean')\n",
    "    nearest_neighbors = np.argsort(distances, axis=1)[:, :3]\n",
    "    \n",
    "    train_labels_int = np.array([label_mapping[label] for label in train_labels])\n",
    "    \n",
    "    # labei\n",
    "    predicted_labels = np.empty((test_data.shape[0],), dtype=train_labels_int.dtype)\n",
    "    \n",
    "    for i, neighbors in enumerate(nearest_neighbors):\n",
    "        if len(neighbors) > 0:\n",
    "            predicted_labels[i] = np.argmax(np.bincount(train_labels_int[neighbors]))\n",
    "        else:\n",
    "            predicted_labels[i] = -1 \n",
    "    \n",
    "    predicted_labels = np.array([inverse_label_mapping[i] for i in predicted_labels])\n",
    "    \n",
    "    return predicted_labels\n",
    "\n",
    "# divide set\n",
    "train_data = data_standardized[train_data_indices, :]\n",
    "test_data = data_standardized[test_data_indices, :]\n",
    "train_labels = labels[train_data_indices]\n",
    "test_labels = labels[test_data_indices]\n",
    "\n",
    "# test\n",
    "for data_pca, dim in zip([data_pca_40, data_pca_80, data_pca_200], [40, 80, 200]):\n",
    "    print(f\"\\nTesting with {dim}-dimensional PCA data:\")\n",
    "    \n",
    "    train_predicted_labels = knn_predict(data_pca[train_data_indices, :], train_labels, data_pca[train_data_indices, :])\n",
    "    train_accuracy = np.mean(train_predicted_labels == train_labels)\n",
    "    \n",
    "    test_predicted_labels = knn_predict(data_pca[train_data_indices, :], train_labels, data_pca[test_data_indices, :])\n",
    "    test_accuracy = np.mean(test_predicted_labels == test_labels)\n",
    "    \n",
    "    print(f\"Train Accuracy = {train_accuracy:.4f}, Test Accuracy = {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1f1e39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
